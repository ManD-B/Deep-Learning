{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 이미지 인식 - CNN\n",
    "## MNIST 사례"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# seed 값 설정\n",
    "seed = 0\n",
    "np.random.seed(seed)\n",
    "tf.random.set_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 불러오기\n",
    "(X_train, Y_train), (X_test, Y_test) = mnist.load_data()\n",
    "X_train = X_train.reshape(X_train.shape[0], 28, 28, 1).astype('float32') / 255\n",
    "X_test = X_test.reshape(X_test.shape[0], 28, 28, 1).astype('float32') / 255\n",
    "Y_train = tf.keras.utils.to_categorical(Y_train)\n",
    "Y_test = tf.keras.utils.to_categorical(Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_4 (Conv2D)            (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 24, 24, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 12, 12, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 12, 12, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 9216)              0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 128)               1179776   \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 1,199,882\n",
      "Trainable params: 1,199,882\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 컨볼루션 신경망 설정\n",
    "model = Sequential([\n",
    "    Conv2D(32, kernel_size=(3, 3), input_shape=(28, 28, 1), activation='relu'),\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    MaxPooling2D(pool_size=2),\n",
    "    Dropout(0.25),\n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(10, activation='softmax')\n",
    "])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 최적화 설정\n",
    "MODEL_DIR = './model/'\n",
    "if not os.path.exists(MODEL_DIR):\n",
    "    os.mkdir(MODEL_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelpath = MODEL_DIR + \"mnist-cnn-{epoch:02d}-{val_loss:.4f}.hdf5\"\n",
    "checkpointer = ModelCheckpoint(filepath=modelpath, monitor='val_loss', \n",
    "                               verbose=1, save_best_only=True)\n",
    "early_stopping_callback = EarlyStopping(monitor='val_loss', patience=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/30\n",
      "59800/60000 [============================>.] - ETA: 0s - loss: 0.2703 - accuracy: 0.9185\n",
      "Epoch 00001: val_loss improved from inf to 0.05459, saving model to ./model/mnist-cnn-01-0.0546.hdf5\n",
      "60000/60000 [==============================] - 40s 674us/sample - loss: 0.2699 - accuracy: 0.9187 - val_loss: 0.0546 - val_accuracy: 0.9814\n",
      "Epoch 2/30\n",
      "59800/60000 [============================>.] - ETA: 0s - loss: 0.0875 - accuracy: 0.9735\n",
      "Epoch 00002: val_loss improved from 0.05459 to 0.04425, saving model to ./model/mnist-cnn-02-0.0442.hdf5\n",
      "60000/60000 [==============================] - 40s 668us/sample - loss: 0.0875 - accuracy: 0.9735 - val_loss: 0.0442 - val_accuracy: 0.9840\n",
      "Epoch 3/30\n",
      "59800/60000 [============================>.] - ETA: 0s - loss: 0.0665 - accuracy: 0.9801\n",
      "Epoch 00003: val_loss improved from 0.04425 to 0.03643, saving model to ./model/mnist-cnn-03-0.0364.hdf5\n",
      "60000/60000 [==============================] - 40s 666us/sample - loss: 0.0665 - accuracy: 0.9801 - val_loss: 0.0364 - val_accuracy: 0.9874\n",
      "Epoch 4/30\n",
      "59800/60000 [============================>.] - ETA: 0s - loss: 0.0537 - accuracy: 0.9838\n",
      "Epoch 00004: val_loss improved from 0.03643 to 0.03330, saving model to ./model/mnist-cnn-04-0.0333.hdf5\n",
      "60000/60000 [==============================] - 40s 669us/sample - loss: 0.0537 - accuracy: 0.9838 - val_loss: 0.0333 - val_accuracy: 0.9882\n",
      "Epoch 5/30\n",
      "59800/60000 [============================>.] - ETA: 0s - loss: 0.0473 - accuracy: 0.9852\n",
      "Epoch 00005: val_loss improved from 0.03330 to 0.03049, saving model to ./model/mnist-cnn-05-0.0305.hdf5\n",
      "60000/60000 [==============================] - 41s 683us/sample - loss: 0.0474 - accuracy: 0.9852 - val_loss: 0.0305 - val_accuracy: 0.9896\n",
      "Epoch 6/30\n",
      "59800/60000 [============================>.] - ETA: 0s - loss: 0.0401 - accuracy: 0.9874\n",
      "Epoch 00006: val_loss improved from 0.03049 to 0.02984, saving model to ./model/mnist-cnn-06-0.0298.hdf5\n",
      "60000/60000 [==============================] - 41s 680us/sample - loss: 0.0402 - accuracy: 0.9874 - val_loss: 0.0298 - val_accuracy: 0.9903\n",
      "Epoch 7/30\n",
      "59800/60000 [============================>.] - ETA: 0s - loss: 0.0352 - accuracy: 0.9888\n",
      "Epoch 00007: val_loss improved from 0.02984 to 0.02809, saving model to ./model/mnist-cnn-07-0.0281.hdf5\n",
      "60000/60000 [==============================] - 41s 680us/sample - loss: 0.0351 - accuracy: 0.9889 - val_loss: 0.0281 - val_accuracy: 0.9908\n",
      "Epoch 8/30\n",
      "59800/60000 [============================>.] - ETA: 0s - loss: 0.0322 - accuracy: 0.9894\n",
      "Epoch 00008: val_loss did not improve from 0.02809\n",
      "60000/60000 [==============================] - 41s 676us/sample - loss: 0.0323 - accuracy: 0.9894 - val_loss: 0.0308 - val_accuracy: 0.9901\n",
      "Epoch 9/30\n",
      "59800/60000 [============================>.] - ETA: 0s - loss: 0.0292 - accuracy: 0.9904\n",
      "Epoch 00009: val_loss did not improve from 0.02809\n",
      "60000/60000 [==============================] - 41s 681us/sample - loss: 0.0291 - accuracy: 0.9904 - val_loss: 0.0288 - val_accuracy: 0.9909\n",
      "Epoch 10/30\n",
      "59800/60000 [============================>.] - ETA: 0s - loss: 0.0266 - accuracy: 0.9914\n",
      "Epoch 00010: val_loss improved from 0.02809 to 0.02723, saving model to ./model/mnist-cnn-10-0.0272.hdf5\n",
      "60000/60000 [==============================] - 41s 677us/sample - loss: 0.0266 - accuracy: 0.9914 - val_loss: 0.0272 - val_accuracy: 0.9915\n",
      "Epoch 11/30\n",
      "59800/60000 [============================>.] - ETA: 0s - loss: 0.0249 - accuracy: 0.9920\n",
      "Epoch 00011: val_loss did not improve from 0.02723\n",
      "60000/60000 [==============================] - 41s 679us/sample - loss: 0.0248 - accuracy: 0.9920 - val_loss: 0.0295 - val_accuracy: 0.9913\n",
      "Epoch 12/30\n",
      "59800/60000 [============================>.] - ETA: 0s - loss: 0.0222 - accuracy: 0.9927\n",
      "Epoch 00012: val_loss did not improve from 0.02723\n",
      "60000/60000 [==============================] - 41s 680us/sample - loss: 0.0223 - accuracy: 0.9927 - val_loss: 0.0274 - val_accuracy: 0.9924\n",
      "Epoch 13/30\n",
      "59800/60000 [============================>.] - ETA: 0s - loss: 0.0222 - accuracy: 0.9924\n",
      "Epoch 00013: val_loss did not improve from 0.02723\n",
      "60000/60000 [==============================] - 40s 672us/sample - loss: 0.0223 - accuracy: 0.9924 - val_loss: 0.0330 - val_accuracy: 0.9905\n",
      "Epoch 14/30\n",
      "59800/60000 [============================>.] - ETA: 0s - loss: 0.0199 - accuracy: 0.9935\n",
      "Epoch 00014: val_loss did not improve from 0.02723\n",
      "60000/60000 [==============================] - 40s 668us/sample - loss: 0.0198 - accuracy: 0.9935 - val_loss: 0.0298 - val_accuracy: 0.9919\n",
      "Epoch 15/30\n",
      "59800/60000 [============================>.] - ETA: 0s - loss: 0.0198 - accuracy: 0.9934\n",
      "Epoch 00015: val_loss did not improve from 0.02723\n",
      "60000/60000 [==============================] - 40s 669us/sample - loss: 0.0198 - accuracy: 0.9934 - val_loss: 0.0300 - val_accuracy: 0.9912\n",
      "Epoch 16/30\n",
      "59800/60000 [============================>.] - ETA: 0s - loss: 0.0187 - accuracy: 0.9935\n",
      "Epoch 00016: val_loss did not improve from 0.02723\n",
      "60000/60000 [==============================] - 40s 663us/sample - loss: 0.0187 - accuracy: 0.9935 - val_loss: 0.0284 - val_accuracy: 0.9920\n",
      "Epoch 17/30\n",
      "59800/60000 [============================>.] - ETA: 0s - loss: 0.0163 - accuracy: 0.9946\n",
      "Epoch 00017: val_loss did not improve from 0.02723\n",
      "60000/60000 [==============================] - 40s 665us/sample - loss: 0.0163 - accuracy: 0.9946 - val_loss: 0.0296 - val_accuracy: 0.9918\n",
      "Epoch 18/30\n",
      "59800/60000 [============================>.] - ETA: 0s - loss: 0.0163 - accuracy: 0.9948\n",
      "Epoch 00018: val_loss did not improve from 0.02723\n",
      "60000/60000 [==============================] - 40s 672us/sample - loss: 0.0163 - accuracy: 0.9948 - val_loss: 0.0293 - val_accuracy: 0.9924\n",
      "Epoch 19/30\n",
      "59800/60000 [============================>.] - ETA: 0s - loss: 0.0141 - accuracy: 0.9951\n",
      "Epoch 00019: val_loss did not improve from 0.02723\n",
      "60000/60000 [==============================] - 40s 663us/sample - loss: 0.0141 - accuracy: 0.9951 - val_loss: 0.0284 - val_accuracy: 0.9927\n",
      "Epoch 20/30\n",
      "59800/60000 [============================>.] - ETA: 0s - loss: 0.0143 - accuracy: 0.9949\n",
      "Epoch 00020: val_loss did not improve from 0.02723\n",
      "60000/60000 [==============================] - 40s 666us/sample - loss: 0.0143 - accuracy: 0.9949 - val_loss: 0.0277 - val_accuracy: 0.9934\n"
     ]
    }
   ],
   "source": [
    "# 모델의 실행\n",
    "history = model.fit(X_train, Y_train, validation_data=(X_test, Y_test), epochs=30,\n",
    "                    batch_size=200, #epochs=5, verbose=2, \n",
    "                    callbacks=[early_stopping_callback, checkpointer])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "del model\n",
    "model = load_model('model/mnist-cnn-10-0.0272.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Test Accuracy: 0.9915\n"
     ]
    }
   ],
   "source": [
    "# 테스트 정확도 출력 \n",
    "print(\"\\n Test Accuracy: %.4f\" % (model.evaluate(X_test, Y_test, verbose=0)[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 테스트셋의 오차\n",
    "y_vloss = history.history['val_loss']\n",
    "\n",
    "# 학습셋의 오차\n",
    "y_loss = history.history['loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 그래프로 표현\n",
    "x_len = np.arange(1, len(y_loss)+1)\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.plot(x_len, y_vloss, marker='.', c=\"red\", label='Testset_loss')\n",
    "plt.plot(x_len, y_loss, marker='.', c=\"blue\", label='Trainset_loss')\n",
    "\n",
    "# 그래프에 그리드를 주고 레이블을 표시\n",
    "plt.legend(loc='upper right')\n",
    "# plt.axis([0, 20, 0, 0.35])\n",
    "plt.grid()\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 결론: Best Model은 Epoch 18, 정확도는 99.29%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
