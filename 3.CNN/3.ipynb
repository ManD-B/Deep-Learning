{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 이미지 인식 - CNN\n",
    "## MNIST 사례"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# seed 값 설정\n",
    "seed = 0\n",
    "np.random.seed(seed)\n",
    "tf.random.set_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 불러오기\n",
    "(X_train, Y_train), (X_test, Y_test) = mnist.load_data()\n",
    "X_train = X_train.reshape(X_train.shape[0], 28, 28, 1).astype('float32') / 255\n",
    "X_test = X_test.reshape(X_test.shape[0], 28, 28, 1).astype('float32') / 255\n",
    "Y_train = tf.keras.utils.to_categorical(Y_train)\n",
    "Y_test = tf.keras.utils.to_categorical(Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_6 (Conv2D)            (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 24, 24, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 12, 12, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 12, 12, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 9216)              0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 128)               1179776   \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 1,207,498\n",
      "Trainable params: 1,207,498\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 컨볼루션 신경망 설정\n",
    "model = Sequential([\n",
    "    Conv2D(32, kernel_size=(3, 3), input_shape=(28, 28, 1), activation='relu'),\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    MaxPooling2D(pool_size=2),\n",
    "    Dropout(0.25),\n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(10, activation='softmax')\n",
    "])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 최적화 설정\n",
    "MODEL_DIR = './model/'\n",
    "if not os.path.exists(MODEL_DIR):\n",
    "    os.mkdir(MODEL_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelpath = MODEL_DIR + \"mnist-cnn-{epoch:02d}-{val_loss:.4f}.hdf5\"\n",
    "checkpointer = ModelCheckpoint(filepath=modelpath, monitor='val_loss', \n",
    "                               verbose=1, save_best_only=True)\n",
    "early_stopping_callback = EarlyStopping(monitor='val_loss', patience=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/30\n",
      "59800/60000 [============================>.] - ETA: 0s - loss: 0.3639 - accuracy: 0.8883\n",
      "Epoch 00001: val_loss improved from inf to 0.06324, saving model to ./model/mnist-cnn-01-0.0632.hdf5\n",
      "60000/60000 [==============================] - 42s 696us/sample - loss: 0.3632 - accuracy: 0.8885 - val_loss: 0.0632 - val_accuracy: 0.9805\n",
      "Epoch 2/30\n",
      "59800/60000 [============================>.] - ETA: 0s - loss: 0.1077 - accuracy: 0.9700\n",
      "Epoch 00002: val_loss improved from 0.06324 to 0.04629, saving model to ./model/mnist-cnn-02-0.0463.hdf5\n",
      "60000/60000 [==============================] - 58s 968us/sample - loss: 0.1076 - accuracy: 0.9700 - val_loss: 0.0463 - val_accuracy: 0.9849\n",
      "Epoch 3/30\n",
      "59800/60000 [============================>.] - ETA: 0s - loss: 0.0713 - accuracy: 0.9802\n",
      "Epoch 00003: val_loss did not improve from 0.04629\n",
      "60000/60000 [==============================] - 103s 2ms/sample - loss: 0.0713 - accuracy: 0.9802 - val_loss: 0.0507 - val_accuracy: 0.9856\n",
      "Epoch 4/30\n",
      "59800/60000 [============================>.] - ETA: 0s - loss: 0.0558 - accuracy: 0.9848\n",
      "Epoch 00004: val_loss improved from 0.04629 to 0.03904, saving model to ./model/mnist-cnn-04-0.0390.hdf5\n",
      "60000/60000 [==============================] - 110s 2ms/sample - loss: 0.0557 - accuracy: 0.9848 - val_loss: 0.0390 - val_accuracy: 0.9884\n",
      "Epoch 5/30\n",
      "59800/60000 [============================>.] - ETA: 0s - loss: 0.0471 - accuracy: 0.9866\n",
      "Epoch 00005: val_loss did not improve from 0.03904\n",
      "60000/60000 [==============================] - 107s 2ms/sample - loss: 0.0471 - accuracy: 0.9866 - val_loss: 0.0404 - val_accuracy: 0.9874\n",
      "Epoch 6/30\n",
      "59800/60000 [============================>.] - ETA: 0s - loss: 0.0404 - accuracy: 0.9886\n",
      "Epoch 00006: val_loss improved from 0.03904 to 0.03218, saving model to ./model/mnist-cnn-06-0.0322.hdf5\n",
      "60000/60000 [==============================] - 105s 2ms/sample - loss: 0.0405 - accuracy: 0.9886 - val_loss: 0.0322 - val_accuracy: 0.9904\n",
      "Epoch 7/30\n",
      "59800/60000 [============================>.] - ETA: 0s - loss: 0.0333 - accuracy: 0.9908\n",
      "Epoch 00007: val_loss did not improve from 0.03218\n",
      "60000/60000 [==============================] - 104s 2ms/sample - loss: 0.0334 - accuracy: 0.9908 - val_loss: 0.0367 - val_accuracy: 0.9887\n",
      "Epoch 8/30\n",
      "59800/60000 [============================>.] - ETA: 0s - loss: 0.0268 - accuracy: 0.9920\n",
      "Epoch 00008: val_loss did not improve from 0.03218\n",
      "60000/60000 [==============================] - 104s 2ms/sample - loss: 0.0270 - accuracy: 0.9919 - val_loss: 0.0333 - val_accuracy: 0.9912\n",
      "Epoch 9/30\n",
      "59800/60000 [============================>.] - ETA: 0s - loss: 0.0231 - accuracy: 0.9931\n",
      "Epoch 00009: val_loss did not improve from 0.03218\n",
      "60000/60000 [==============================] - 102s 2ms/sample - loss: 0.0231 - accuracy: 0.9931 - val_loss: 0.0349 - val_accuracy: 0.9910\n",
      "Epoch 10/30\n",
      "59800/60000 [============================>.] - ETA: 0s - loss: 0.0221 - accuracy: 0.9936\n",
      "Epoch 00010: val_loss did not improve from 0.03218\n",
      "60000/60000 [==============================] - 104s 2ms/sample - loss: 0.0220 - accuracy: 0.9936 - val_loss: 0.0382 - val_accuracy: 0.9895\n",
      "Epoch 11/30\n",
      "59800/60000 [============================>.] - ETA: 0s - loss: 0.0180 - accuracy: 0.9950\n",
      "Epoch 00011: val_loss did not improve from 0.03218\n",
      "60000/60000 [==============================] - 105s 2ms/sample - loss: 0.0179 - accuracy: 0.9950 - val_loss: 0.0401 - val_accuracy: 0.9898\n",
      "Epoch 12/30\n",
      "59800/60000 [============================>.] - ETA: 0s - loss: 0.0178 - accuracy: 0.9947\n",
      "Epoch 00012: val_loss did not improve from 0.03218\n",
      "60000/60000 [==============================] - 104s 2ms/sample - loss: 0.0178 - accuracy: 0.9947 - val_loss: 0.0375 - val_accuracy: 0.9906\n",
      "Epoch 13/30\n",
      "59800/60000 [============================>.] - ETA: 0s - loss: 0.0166 - accuracy: 0.9951\n",
      "Epoch 00013: val_loss did not improve from 0.03218\n",
      "60000/60000 [==============================] - 104s 2ms/sample - loss: 0.0166 - accuracy: 0.9951 - val_loss: 0.0442 - val_accuracy: 0.9890\n",
      "Epoch 14/30\n",
      "59800/60000 [============================>.] - ETA: 0s - loss: 0.0148 - accuracy: 0.9958\n",
      "Epoch 00014: val_loss did not improve from 0.03218\n",
      "60000/60000 [==============================] - 103s 2ms/sample - loss: 0.0147 - accuracy: 0.9958 - val_loss: 0.0499 - val_accuracy: 0.9890\n",
      "Epoch 15/30\n",
      "59800/60000 [============================>.] - ETA: 0s - loss: 0.0133 - accuracy: 0.9962\n",
      "Epoch 00015: val_loss did not improve from 0.03218\n",
      "60000/60000 [==============================] - 103s 2ms/sample - loss: 0.0134 - accuracy: 0.9962 - val_loss: 0.0378 - val_accuracy: 0.9912\n",
      "Epoch 16/30\n",
      "59800/60000 [============================>.] - ETA: 0s - loss: 0.0121 - accuracy: 0.9966\n",
      "Epoch 00016: val_loss did not improve from 0.03218\n",
      "60000/60000 [==============================] - 103s 2ms/sample - loss: 0.0121 - accuracy: 0.9966 - val_loss: 0.0435 - val_accuracy: 0.9901\n"
     ]
    }
   ],
   "source": [
    "# 모델의 실행\n",
    "history = model.fit(X_train, Y_train, validation_data=(X_test, Y_test), epochs=30,\n",
    "                    batch_size=200, #epochs=5, verbose=2, \n",
    "                    callbacks=[early_stopping_callback, checkpointer])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "del model\n",
    "model = load_model('model/mnist-cnn-10-0.0272.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Test Accuracy: 0.9915\n"
     ]
    }
   ],
   "source": [
    "# 테스트 정확도 출력 \n",
    "print(\"\\n Test Accuracy: %.4f\" % (model.evaluate(X_test, Y_test, verbose=0)[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 테스트셋의 오차\n",
    "y_vloss = history.history['val_loss']\n",
    "\n",
    "# 학습셋의 오차\n",
    "y_loss = history.history['loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 그래프로 표현\n",
    "x_len = np.arange(1, len(y_loss)+1)\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.plot(x_len, y_vloss, marker='.', c=\"red\", label='Testset_loss')\n",
    "plt.plot(x_len, y_loss, marker='.', c=\"blue\", label='Trainset_loss')\n",
    "\n",
    "# 그래프에 그리드를 주고 레이블을 표시\n",
    "plt.legend(loc='upper right')\n",
    "# plt.axis([0, 20, 0, 0.35])\n",
    "plt.grid()\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 결론: Best Model은 Epoch 18, 정확도는 99.29%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
