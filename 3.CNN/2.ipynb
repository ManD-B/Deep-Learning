{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 이미지 인식 - CNN\n",
    "## MNIST 사례"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# seed 값 설정\n",
    "seed = 0\n",
    "np.random.seed(seed)\n",
    "tf.random.set_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 불러오기\n",
    "(X_train, Y_train), (X_test, Y_test) = mnist.load_data()\n",
    "X_train = X_train.reshape(X_train.shape[0], 28, 28, 1).astype('float32') / 255\n",
    "X_test = X_test.reshape(X_test.shape[0], 28, 28, 1).astype('float32') / 255\n",
    "Y_train = tf.keras.utils.to_categorical(Y_train)\n",
    "Y_test = tf.keras.utils.to_categorical(Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_2 (Conv2D)            (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 24, 24, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 12, 12, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 12, 12, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 9216)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 128)               1179776   \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 1,199,882\n",
      "Trainable params: 1,199,882\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 컨볼루션 신경망 설정\n",
    "model = Sequential([\n",
    "    Conv2D(32, kernel_size=(3, 3), input_shape=(28, 28, 1), activation='relu'),\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    MaxPooling2D(pool_size=2),\n",
    "    Dropout(0.5),\n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.25),\n",
    "    Dense(10, activation='softmax')\n",
    "])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 최적화 설정\n",
    "MODEL_DIR = './model2/'\n",
    "if not os.path.exists(MODEL_DIR):\n",
    "    os.mkdir(MODEL_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelpath = MODEL_DIR + \"mnist-cnn-{epoch:02d}-{val_loss:.4f}.hdf5\"\n",
    "checkpointer = ModelCheckpoint(filepath=modelpath, monitor='val_loss', \n",
    "                               verbose=1, save_best_only=True)\n",
    "early_stopping_callback = EarlyStopping(monitor='val_loss', patience=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/30\n",
      "59800/60000 [============================>.] - ETA: 0s - loss: 0.2309 - accuracy: 0.9296\n",
      "Epoch 00001: val_loss improved from inf to 0.05840, saving model to ./model2/mnist-cnn-01-0.0584.hdf5\n",
      "60000/60000 [==============================] - 85s 1ms/sample - loss: 0.2306 - accuracy: 0.9297 - val_loss: 0.0584 - val_accuracy: 0.9817\n",
      "Epoch 2/30\n",
      "59800/60000 [============================>.] - ETA: 0s - loss: 0.0698 - accuracy: 0.9785\n",
      "Epoch 00002: val_loss improved from 0.05840 to 0.03705, saving model to ./model2/mnist-cnn-02-0.0370.hdf5\n",
      "60000/60000 [==============================] - 105s 2ms/sample - loss: 0.0699 - accuracy: 0.9784 - val_loss: 0.0370 - val_accuracy: 0.9863\n",
      "Epoch 3/30\n",
      "59800/60000 [============================>.] - ETA: 0s - loss: 0.0515 - accuracy: 0.9838\n",
      "Epoch 00003: val_loss improved from 0.03705 to 0.03390, saving model to ./model2/mnist-cnn-03-0.0339.hdf5\n",
      "60000/60000 [==============================] - 105s 2ms/sample - loss: 0.0515 - accuracy: 0.9838 - val_loss: 0.0339 - val_accuracy: 0.9885\n",
      "Epoch 4/30\n",
      "59800/60000 [============================>.] - ETA: 0s - loss: 0.0402 - accuracy: 0.9876\n",
      "Epoch 00004: val_loss improved from 0.03390 to 0.03075, saving model to ./model2/mnist-cnn-04-0.0308.hdf5\n",
      "60000/60000 [==============================] - 108s 2ms/sample - loss: 0.0401 - accuracy: 0.9876 - val_loss: 0.0308 - val_accuracy: 0.9891\n",
      "Epoch 5/30\n",
      "59800/60000 [============================>.] - ETA: 0s - loss: 0.0344 - accuracy: 0.9888\n",
      "Epoch 00005: val_loss improved from 0.03075 to 0.02885, saving model to ./model2/mnist-cnn-05-0.0288.hdf5\n",
      "60000/60000 [==============================] - 104s 2ms/sample - loss: 0.0345 - accuracy: 0.9888 - val_loss: 0.0288 - val_accuracy: 0.9906\n",
      "Epoch 6/30\n",
      "59800/60000 [============================>.] - ETA: 0s - loss: 0.0301 - accuracy: 0.9903\n",
      "Epoch 00006: val_loss improved from 0.02885 to 0.02570, saving model to ./model2/mnist-cnn-06-0.0257.hdf5\n",
      "60000/60000 [==============================] - 103s 2ms/sample - loss: 0.0302 - accuracy: 0.9903 - val_loss: 0.0257 - val_accuracy: 0.9914\n",
      "Epoch 7/30\n",
      "59800/60000 [============================>.] - ETA: 0s - loss: 0.0260 - accuracy: 0.9918\n",
      "Epoch 00007: val_loss did not improve from 0.02570\n",
      "60000/60000 [==============================] - 103s 2ms/sample - loss: 0.0259 - accuracy: 0.9918 - val_loss: 0.0292 - val_accuracy: 0.9899\n",
      "Epoch 8/30\n",
      "59800/60000 [============================>.] - ETA: 0s - loss: 0.0235 - accuracy: 0.9925\n",
      "Epoch 00008: val_loss did not improve from 0.02570\n",
      "60000/60000 [==============================] - 105s 2ms/sample - loss: 0.0239 - accuracy: 0.9924 - val_loss: 0.0279 - val_accuracy: 0.9904\n",
      "Epoch 9/30\n",
      "59800/60000 [============================>.] - ETA: 0s - loss: 0.0215 - accuracy: 0.9928\n",
      "Epoch 00009: val_loss did not improve from 0.02570\n",
      "60000/60000 [==============================] - 103s 2ms/sample - loss: 0.0214 - accuracy: 0.9928 - val_loss: 0.0264 - val_accuracy: 0.9920\n",
      "Epoch 10/30\n",
      "59800/60000 [============================>.] - ETA: 0s - loss: 0.0186 - accuracy: 0.9939\n",
      "Epoch 00010: val_loss did not improve from 0.02570\n",
      "60000/60000 [==============================] - 104s 2ms/sample - loss: 0.0185 - accuracy: 0.9940 - val_loss: 0.0275 - val_accuracy: 0.9919\n",
      "Epoch 11/30\n",
      "59800/60000 [============================>.] - ETA: 0s - loss: 0.0184 - accuracy: 0.9939\n",
      "Epoch 00011: val_loss did not improve from 0.02570\n",
      "60000/60000 [==============================] - 103s 2ms/sample - loss: 0.0184 - accuracy: 0.9940 - val_loss: 0.0272 - val_accuracy: 0.9917\n",
      "Epoch 12/30\n",
      "59800/60000 [============================>.] - ETA: 0s - loss: 0.0169 - accuracy: 0.9937\n",
      "Epoch 00012: val_loss improved from 0.02570 to 0.02429, saving model to ./model2/mnist-cnn-12-0.0243.hdf5\n",
      "60000/60000 [==============================] - 104s 2ms/sample - loss: 0.0169 - accuracy: 0.9937 - val_loss: 0.0243 - val_accuracy: 0.9927\n",
      "Epoch 13/30\n",
      "59800/60000 [============================>.] - ETA: 0s - loss: 0.0159 - accuracy: 0.9943\n",
      "Epoch 00013: val_loss did not improve from 0.02429\n",
      "60000/60000 [==============================] - 104s 2ms/sample - loss: 0.0159 - accuracy: 0.9943 - val_loss: 0.0279 - val_accuracy: 0.9927\n",
      "Epoch 14/30\n",
      "59800/60000 [============================>.] - ETA: 0s - loss: 0.0140 - accuracy: 0.9955\n",
      "Epoch 00014: val_loss did not improve from 0.02429\n",
      "60000/60000 [==============================] - 104s 2ms/sample - loss: 0.0140 - accuracy: 0.9955 - val_loss: 0.0293 - val_accuracy: 0.9920\n",
      "Epoch 15/30\n",
      "59800/60000 [============================>.] - ETA: 0s - loss: 0.0128 - accuracy: 0.9957\n",
      "Epoch 00015: val_loss did not improve from 0.02429\n",
      "60000/60000 [==============================] - 90s 1ms/sample - loss: 0.0128 - accuracy: 0.9957 - val_loss: 0.0263 - val_accuracy: 0.9926\n",
      "Epoch 16/30\n",
      "59800/60000 [============================>.] - ETA: 0s - loss: 0.0122 - accuracy: 0.9956\n",
      "Epoch 00016: val_loss did not improve from 0.02429\n",
      "60000/60000 [==============================] - 71s 1ms/sample - loss: 0.0122 - accuracy: 0.9956 - val_loss: 0.0285 - val_accuracy: 0.9926\n",
      "Epoch 17/30\n",
      "59800/60000 [============================>.] - ETA: 0s - loss: 0.0114 - accuracy: 0.9962\n",
      "Epoch 00017: val_loss did not improve from 0.02429\n",
      "60000/60000 [==============================] - 70s 1ms/sample - loss: 0.0114 - accuracy: 0.9962 - val_loss: 0.0261 - val_accuracy: 0.9934\n",
      "Epoch 18/30\n",
      "59800/60000 [============================>.] - ETA: 0s - loss: 0.0125 - accuracy: 0.9957\n",
      "Epoch 00018: val_loss did not improve from 0.02429\n",
      "60000/60000 [==============================] - 71s 1ms/sample - loss: 0.0124 - accuracy: 0.9957 - val_loss: 0.0269 - val_accuracy: 0.9927\n",
      "Epoch 19/30\n",
      "59800/60000 [============================>.] - ETA: 0s - loss: 0.0112 - accuracy: 0.9961\n",
      "Epoch 00019: val_loss did not improve from 0.02429\n",
      "60000/60000 [==============================] - 71s 1ms/sample - loss: 0.0112 - accuracy: 0.9961 - val_loss: 0.0284 - val_accuracy: 0.9929\n",
      "Epoch 20/30\n",
      "59800/60000 [============================>.] - ETA: 0s - loss: 0.0109 - accuracy: 0.9961\n",
      "Epoch 00020: val_loss did not improve from 0.02429\n",
      "60000/60000 [==============================] - 75s 1ms/sample - loss: 0.0109 - accuracy: 0.9961 - val_loss: 0.0303 - val_accuracy: 0.9923\n",
      "Epoch 21/30\n",
      "59800/60000 [============================>.] - ETA: 0s - loss: 0.0113 - accuracy: 0.9965\n",
      "Epoch 00021: val_loss did not improve from 0.02429\n",
      "60000/60000 [==============================] - 45s 755us/sample - loss: 0.0113 - accuracy: 0.9965 - val_loss: 0.0316 - val_accuracy: 0.9919\n",
      "Epoch 22/30\n",
      "59800/60000 [============================>.] - ETA: 0s - loss: 0.0095 - accuracy: 0.9966\n",
      "Epoch 00022: val_loss did not improve from 0.02429\n",
      "60000/60000 [==============================] - 41s 677us/sample - loss: 0.0095 - accuracy: 0.9966 - val_loss: 0.0321 - val_accuracy: 0.9926\n"
     ]
    }
   ],
   "source": [
    "# 모델의 실행\n",
    "history = model.fit(X_train, Y_train, validation_data=(X_test, Y_test), epochs=30,\n",
    "                    batch_size=200, #epochs=5, verbose=2, \n",
    "                    callbacks=[early_stopping_callback, checkpointer])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "del model\n",
    "model = load_model('model2/mnist-cnn-12-0.0243.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Test Accuracy: 0.9927\n"
     ]
    }
   ],
   "source": [
    "# 테스트 정확도 출력 \n",
    "print(\"\\n Test Accuracy: %.4f\" % (model.evaluate(X_test, Y_test, verbose=0)[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 테스트셋의 오차\n",
    "y_vloss = history.history['val_loss']\n",
    "\n",
    "# 학습셋의 오차\n",
    "y_loss = history.history['loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 그래프로 표현\n",
    "x_len = np.arange(1, len(y_loss)+1)\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.plot(x_len, y_vloss, marker='.', c=\"red\", label='Testset_loss')\n",
    "plt.plot(x_len, y_loss, marker='.', c=\"blue\", label='Trainset_loss')\n",
    "\n",
    "# 그래프에 그리드를 주고 레이블을 표시\n",
    "plt.legend(loc='upper right')\n",
    "# plt.axis([0, 20, 0, 0.35])\n",
    "plt.grid()\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 결론: Best Model은 Epoch 18, 정확도는 99.29%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
